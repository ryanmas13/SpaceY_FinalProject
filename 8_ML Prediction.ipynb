{"cells":[{"cell_type":"markdown","id":"45128cec-7a53-49d4-9385-7808786c8587","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"14e4a2ce-9a23-4ee1-a636-1991d2d3b0a0","metadata":{},"source":["# **Space X  Falcon 9 First Stage Landing Prediction**\n"]},{"cell_type":"markdown","id":"d2e4a8b5-9d30-44b4-916f-73e01e9e8840","metadata":{},"source":["## Assignment:  Machine Learning Prediction\n"]},{"cell_type":"markdown","id":"b5725c6b-bf28-4ba0-833b-7554a2730d9a","metadata":{},"source":["Estimated time needed: **60** minutes\n"]},{"cell_type":"markdown","id":"c3fac55f-5ff1-49dd-aaa6-2c7807333851","metadata":{},"source":["Space X advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars; other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. Therefore if we can determine if the first stage will land, we can determine the cost of a launch. This information can be used if an alternate company wants to bid against space X for a rocket launch.   In this lab, you will create a machine learning pipeline  to predict if the first stage will land given the data from the preceding labs.\n"]},{"cell_type":"markdown","id":"e87c7d9a-7dd4-463b-877e-8e734cd9d3c7","metadata":{},"source":["![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing_1.gif)\n"]},{"cell_type":"markdown","id":"894df8c4-9841-4ee7-999d-8001754f3580","metadata":{},"source":["Several examples of an unsuccessful landing are shown here:\n"]},{"cell_type":"markdown","id":"0e0e1c50-2c77-4adf-92bd-65bb6296054c","metadata":{},"source":["![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n"]},{"cell_type":"markdown","id":"2956005c-01b0-4198-9cde-0e07a9ae5db6","metadata":{},"source":["Most unsuccessful landings are planed. Space X; performs a controlled landing in the oceans.\n"]},{"cell_type":"markdown","id":"6a1a7fa0-fa27-4198-a7d7-2923a86e2805","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","id":"554cc19e-9f87-4616-977e-0d0a12df3bb0","metadata":{},"source":["Perform exploratory  Data Analysis and determine Training Labels\n","\n","*   create a column for the class\n","*   Standardize the data\n","*   Split into training data and test data\n","\n","\\-Find best Hyperparameter for SVM, Classification Trees and Logistic Regression\n","\n","*   Find the method performs best using test data\n"]},{"cell_type":"markdown","id":"9a759f39-8110-4550-86b1-8d3b433e80d9","metadata":{},"source":["## Import Libraries and Define Auxiliary Functions\n"]},{"cell_type":"code","execution_count":33,"id":"e3da4e62-7fac-4d28-9d9b-1b3b438f8e32","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)\n","^C\n","Requirement already satisfied: pandas in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n","Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ryanm\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\ryanm\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: seaborn in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.1.1)\n","Requirement already satisfied: pandas>=1.2 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.2.3)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (3.9.2)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\ryanm\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n","Requirement already satisfied: pillow>=8 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ryanm\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\ryanm\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n","Requirement already satisfied: scikit-learn in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.1.1)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n"]}],"source":["!pip install numpy\n","!pip install pandas\n","!pip install seaborn\n","!pip install scikit-learn"]},{"cell_type":"markdown","id":"7c4c7e22-3f15-4df7-9fc7-5b29bc670b6b","metadata":{},"source":["We will import the following libraries for the lab\n"]},{"cell_type":"code","execution_count":2,"id":"b65b0065-ed32-4e4b-a226-56a6cf9c9b51","metadata":{},"outputs":[],"source":["# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n","import pandas as pd\n","# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n","import numpy as np\n","# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n","import matplotlib.pyplot as plt\n","#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n","import seaborn as sns\n","# Preprocessing allows us to standardize our data\n","from sklearn import preprocessing\n","# Allows us to split our data into training and testing data\n","from sklearn.model_selection import train_test_split\n","# Allows us to test parameters of classification algorithms and find the best one\n","from sklearn.model_selection import GridSearchCV\n","# Logistic Regression classification algorithm\n","from sklearn.linear_model import LogisticRegression\n","# Support Vector Machine classification algorithm\n","from sklearn.svm import SVC\n","# Decision Tree classification algorithm\n","from sklearn.tree import DecisionTreeClassifier\n","# K Nearest Neighbors classification algorithm\n","from sklearn.neighbors import KNeighborsClassifier\n","# Classifcation report to compare performance \n","from sklearn.metrics import classification_report"]},{"cell_type":"markdown","id":"fb4ac700-56c8-4ec9-890d-e9c1273c44e3","metadata":{},"source":["This function is to plot the confusion matrix.\n"]},{"cell_type":"code","execution_count":3,"id":"60c635b3-7468-4cb6-9457-87d665e2b3a2","metadata":{},"outputs":[],"source":["def plot_confusion_matrix(y,y_predict):\n","    \"this function plots the confusion matrix\"\n","    from sklearn.metrics import confusion_matrix\n","\n","    cm = confusion_matrix(y, y_predict)\n","    ax= plt.subplot()\n","    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n","    ax.set_xlabel('Predicted labels')\n","    ax.set_ylabel('True labels')\n","    ax.set_title('Confusion Matrix'); \n","    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed']) \n","    plt.show() "]},{"cell_type":"markdown","id":"9cf41a8c-6997-4334-8f40-370a07905c5f","metadata":{},"source":["## Load the dataframe\n"]},{"cell_type":"markdown","id":"8415f28f-944f-45a4-ae29-cf8ff4a58797","metadata":{},"source":["Load the data\n"]},{"cell_type":"code","execution_count":4,"id":"1ef231c6-4d00-46d6-a8d9-4eec1d42244b","metadata":{},"outputs":[],"source":["data = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\")\n"]},{"cell_type":"code","execution_count":null,"id":"7680621f-540b-49d6-a659-47fd9495fb1c","metadata":{},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":6,"id":"15ef074a-bed7-4f3a-a7a1-bd9bf700dba9","metadata":{},"outputs":[],"source":["\n","X = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv')"]},{"cell_type":"code","execution_count":null,"id":"d1e18a7f-2f51-45ae-92d2-b11dfcc35ae3","metadata":{},"outputs":[],"source":["X.head(100)"]},{"cell_type":"markdown","id":"09d2b711-3cee-4b10-82dc-d4ebdcda7726","metadata":{},"source":["## TASK  1\n"]},{"cell_type":"markdown","id":"5da80b90-5ea2-4cbc-8813-1964f3508024","metadata":{},"source":["Create a NumPy array from the column <code>Class</code> in <code>data</code>, by applying the method <code>to_numpy()</code>  then\n","assign it  to the variable <code>Y</code>,make sure the output is a  Pandas series (only one bracket df\\['name of  column']).\n"]},{"cell_type":"code","execution_count":8,"id":"493f312c-cbcb-4ca8-8746-eea4675190cc","metadata":{},"outputs":[],"source":["Y = data[\"Class\"].to_numpy()"]},{"cell_type":"markdown","id":"78f760c8-0d47-400d-8b24-059c2d9ee227","metadata":{},"source":["## TASK  2\n"]},{"cell_type":"markdown","id":"fc36f63f-f1cb-49c6-8eab-a2b16f367331","metadata":{},"source":["Standardize the data in <code>X</code> then reassign it to the variable  <code>X</code> using the transform provided below.\n"]},{"cell_type":"code","execution_count":9,"id":"d5bd70de-d66b-4c64-9737-70e4006d3a29","metadata":{},"outputs":[],"source":["# students get this \n","transform = preprocessing.StandardScaler()\n","\n","X = transform.fit_transform(X)"]},{"cell_type":"markdown","id":"4f124065-3bbf-4bc2-a4b5-2f1cbc1cca81","metadata":{},"source":["We split the data into training and testing data using the  function  <code>train_test_split</code>.   The training data is divided into validation data, a second set used for training  data; then the models are trained and hyperparameters are selected using the function <code>GridSearchCV</code>.\n"]},{"cell_type":"markdown","id":"b9e46dc8-cbd2-479d-baa0-44bbcee60895","metadata":{},"source":["## TASK  3\n"]},{"cell_type":"markdown","id":"a3e2d9c8-c512-4474-8706-4f718f33e6bf","metadata":{},"source":["Use the function train_test_split to split the data X and Y into training and test data. Set the parameter test_size to  0.2 and random_state to 2. The training data and test data should be assigned to the following labels.\n"]},{"cell_type":"markdown","id":"356abb34-42ca-4722-a235-38e2e098d651","metadata":{},"source":["<code>X_train, X_test, Y_train, Y_test</code>\n"]},{"cell_type":"code","execution_count":10,"id":"38018f9e-56d6-48b6-b919-cc13c90c0ed6","metadata":{},"outputs":[],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"]},{"cell_type":"markdown","id":"85d3524c-9622-43ba-9cbb-4103e999e048","metadata":{},"source":["we can see we only have 18 test samples.\n"]},{"cell_type":"code","execution_count":null,"id":"8bcbb0b4-ed3a-424e-86af-aa834d9fd057","metadata":{},"outputs":[],"source":["Y_test.shape"]},{"cell_type":"markdown","id":"e0611f35-2ce5-4b85-9c72-d7623d55cd4a","metadata":{},"source":["## TASK  4\n"]},{"cell_type":"markdown","id":"11c69294-e0a1-41c4-bc68-fdf8de5514e5","metadata":{},"source":["Create a logistic regression object  then create a  GridSearchCV object  <code>logreg_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"]},{"cell_type":"code","execution_count":12,"id":"3dbd0aee-c052-4b5a-8e22-9aa47df635c8","metadata":{},"outputs":[],"source":["parameters ={'C':[0.01,0.1,1],\n","             'penalty':['l2'],\n","             'solver':['lbfgs']}"]},{"cell_type":"code","execution_count":null,"id":"2f6bef5e-bff6-4adc-959f-35d98e1d627a","metadata":{},"outputs":[],"source":["parameters ={\"C\":[0.01,0.1,1],'penalty':['l2'], 'solver':['lbfgs']}# l1 lasso l2 ridge\n","lr=LogisticRegression()\n","logreg_cv = GridSearchCV(estimator=lr, param_grid=parameters, cv=10)\n","logreg_cv.fit(X_train,Y_train)"]},{"cell_type":"markdown","id":"061c6493-76f3-456c-b7ff-e7b0e4dddb79","metadata":{},"source":["We output the <code>GridSearchCV</code> object for logistic regression. We display the best parameters using the data attribute <code>best_params\\_</code> and the accuracy on the validation data using the data attribute <code>best_score\\_</code>.\n"]},{"cell_type":"code","execution_count":null,"id":"da72287f-881e-45a8-b0f3-f895437d2130","metadata":{},"outputs":[],"source":["print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n","print(\"accuracy :\",logreg_cv.best_score_)"]},{"cell_type":"markdown","id":"7dae1cb7-9c9c-455b-b793-9f15dbf7a251","metadata":{},"source":["## TASK  5\n"]},{"cell_type":"markdown","id":"3fa9c0f6-cb18-4ffb-b9c7-b393ed21fe5e","metadata":{},"source":["Calculate the accuracy on the test data using the method <code>score</code>:\n"]},{"cell_type":"code","execution_count":null,"id":"d5bd396d-6c05-46af-93b9-0194bb9c9e36","metadata":{},"outputs":[],"source":["logreg_test_score = logreg_cv.score(X_test, Y_test)\n","print(\"accuracy with the test data is, \", logreg_test_score)"]},{"cell_type":"markdown","id":"2e25a155-ade2-408b-92a7-91eab7f67f00","metadata":{},"source":["Lets look at the confusion matrix:\n"]},{"cell_type":"code","execution_count":null,"id":"1c9c4257-e41b-4a34-a498-ccf1ff95b797","metadata":{},"outputs":[],"source":["yhat=logreg_cv.predict(X_test)\n","logreg_report = classification_report(Y_test, yhat)\n","print(logreg_report)\n","plot_confusion_matrix(Y_test,yhat)"]},{"cell_type":"markdown","id":"229ac8aa-cc70-434f-8547-8078121bdf4a","metadata":{},"source":["Examining the confusion matrix, we see that logistic regression can distinguish between the different classes.  We see that the problem is false positives.\n","\n","Overview:\n","\n","True Postive - 12 (True label is landed, Predicted label is also landed)\n","\n","False Postive - 3 (True label is not landed, Predicted label is landed)\n"]},{"cell_type":"markdown","id":"87e03400-f9e5-4fbb-8707-64b76cd783b7","metadata":{},"source":["## TASK  6\n"]},{"cell_type":"markdown","id":"81052dd2-78c1-413d-8162-67216739f96f","metadata":{},"source":["Create a support vector machine object then  create a  <code>GridSearchCV</code> object  <code>svm_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"]},{"cell_type":"code","execution_count":17,"id":"956dff09-e755-479a-bb26-cbc5a7586704","metadata":{},"outputs":[],"source":["parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n","              'C': np.logspace(-3, 3, 5),\n","              'gamma':np.logspace(-3, 3, 5)}\n","svm = SVC()"]},{"cell_type":"code","execution_count":null,"id":"d1934635-d719-47fc-8172-f6997da9db73","metadata":{},"outputs":[],"source":["svm_cv = GridSearchCV(\n","    estimator=svm,\n","    param_grid=parameters, \n","    cv=10\n",")\n","svm_cv.fit(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"id":"794c4323-611f-420f-858a-5b16e3478fd1","metadata":{},"outputs":[],"source":["print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\n","print(\"accuracy :\",svm_cv.best_score_)"]},{"cell_type":"markdown","id":"149abc05-6f06-44a9-a682-87de7d2c7590","metadata":{},"source":["## TASK  7\n"]},{"cell_type":"markdown","id":"0392fff6-36d1-4006-ad9c-f5fffe942d1f","metadata":{},"source":["Calculate the accuracy on the test data using the method <code>score</code>:\n"]},{"cell_type":"code","execution_count":null,"id":"39ff62e8-4576-4b04-9fd6-640b14c491dd","metadata":{},"outputs":[],"source":["svm_test_score = svm_cv.score(X_test, Y_test)\n","print(\"accuracy with test data\", svm_test_score)"]},{"cell_type":"markdown","id":"7ebe0094-ff2b-4602-8151-51875ffb9a02","metadata":{},"source":["We can plot the confusion matrix\n"]},{"cell_type":"code","execution_count":null,"id":"e310fd5e-9f25-46f6-9c8d-c60c08635823","metadata":{},"outputs":[],"source":["yhat=svm_cv.predict(X_test)\n","svm_report = classification_report(Y_test, yhat)\n","print(svm_report)\n","plot_confusion_matrix(Y_test,yhat)"]},{"cell_type":"markdown","id":"5f8f3baf-ebbc-4857-ad4f-6cabe97b1927","metadata":{},"source":["## TASK  8\n"]},{"cell_type":"markdown","id":"0e280456-e644-4116-a32c-da0b460ead22","metadata":{},"source":["Create a decision tree classifier object then  create a  <code>GridSearchCV</code> object  <code>tree_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"]},{"cell_type":"code","execution_count":22,"id":"c9c52cfb-dbea-45ea-9018-d7bb5961e2a6","metadata":{},"outputs":[],"source":["parameters = {'criterion': ['gini', 'entropy'],\n","     'splitter': ['best', 'random'],\n","     'max_depth': [2*n for n in range(1,10)],\n","     'max_features': ['auto', 'sqrt'],\n","     'min_samples_leaf': [1, 2, 4],\n","     'min_samples_split': [2, 5, 10]}\n","\n","tree = DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"id":"b8da3dd1-f108-4da5-aa35-bc8c787abd2c","metadata":{},"outputs":[],"source":["tree_cv = GridSearchCV(\n","    estimator=tree, \n","    param_grid=parameters,\n","    cv=10\n",")\n","tree_cv.fit(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"id":"298cc719-ee34-4da5-a25a-30a3ba79992e","metadata":{},"outputs":[],"source":["print(\"tuned hpyerparameters :(best parameters) \",tree_cv.best_params_)\n","print(\"accuracy :\",tree_cv.best_score_)"]},{"cell_type":"markdown","id":"aef9dc54-188a-43f3-84ae-dd75fe680db6","metadata":{},"source":["## TASK  9\n"]},{"cell_type":"markdown","id":"58a966fd-f18c-4831-97aa-6421dffa2c6b","metadata":{},"source":["Calculate the accuracy of tree_cv on the test data using the method <code>score</code>:\n"]},{"cell_type":"code","execution_count":null,"id":"a14aa5a1-f00f-47e3-a878-f8217c82661f","metadata":{},"outputs":[],"source":["tree_test_score = tree_cv.score(X_test, Y_test)\n","print(\"accuracy on test data with Decision Tree and Grid Search \", tree_test_score)"]},{"cell_type":"markdown","id":"637e5515-4ef8-42d7-8b94-d512c80420d1","metadata":{},"source":["We can plot the confusion matrix\n"]},{"cell_type":"code","execution_count":null,"id":"1f6297c7-480c-4522-9249-c63511141b32","metadata":{},"outputs":[],"source":["yhat = tree_cv.predict(X_test)\n","tree_report = classification_report(Y_test, yhat)\n","print(tree_report)\n","plot_confusion_matrix(Y_test,yhat)"]},{"cell_type":"markdown","id":"a2311753-4a71-4506-8ffd-255399baff0d","metadata":{},"source":["## TASK  10\n"]},{"cell_type":"markdown","id":"9100e538-7a47-4dfc-8778-5bfe60f54b58","metadata":{},"source":["Create a k nearest neighbors object then  create a  <code>GridSearchCV</code> object  <code>knn_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"]},{"cell_type":"code","execution_count":27,"id":"a65cb7a8-f644-4500-a3bc-6d84995a370b","metadata":{},"outputs":[],"source":["parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n","              'p': [1,2]}\n","\n","KNN = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"id":"36ff9830-a4d5-43e2-bc5d-9d9e17054757","metadata":{},"outputs":[],"source":["knn_cv = GridSearchCV(\n","    estimator=KNN,\n","    param_grid=parameters, \n","    cv=10\n",")\n","\n","knn_cv.fit(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"id":"007ec161-aadc-4582-9f45-312d3bd9fac2","metadata":{},"outputs":[],"source":["print(\"tuned hpyerparameters :(best parameters) \",knn_cv.best_params_)\n","print(\"accuracy :\",knn_cv.best_score_)"]},{"cell_type":"markdown","id":"26d95bf7-8df7-4e35-99c1-503c03bceb53","metadata":{},"source":["## TASK  11\n"]},{"cell_type":"markdown","id":"a195c86d-3ed3-4c55-b8e4-977e40a162d9","metadata":{},"source":["Calculate the accuracy of knn_cv on the test data using the method <code>score</code>:\n"]},{"cell_type":"code","execution_count":null,"id":"7bcf7dd2-ae82-48c4-ae9f-e49e2d204f7a","metadata":{},"outputs":[],"source":["knn_test_score = knn_cv.score(X_test, Y_test)\n","print(\"The accuracy of the test data with KNN and GridSearch is \", knn_test_score)"]},{"cell_type":"markdown","id":"9b0a72e8-56d6-439c-a027-002cd1ca4b96","metadata":{},"source":["We can plot the confusion matrix\n"]},{"cell_type":"code","execution_count":null,"id":"dd552c68-0b76-4499-8ac5-fe9cde84c3d5","metadata":{},"outputs":[],"source":["yhat = knn_cv.predict(X_test)\n","knn_report = classification_report(Y_test, yhat)\n","print(knn_report)\n","plot_confusion_matrix(Y_test,yhat)"]},{"cell_type":"markdown","id":"562109ff-13f3-4387-820b-a9795991caff","metadata":{},"source":["## TASK  12\n"]},{"cell_type":"markdown","id":"35b38fa3-483d-47e2-acb7-9ffaf4f622af","metadata":{},"source":["Find the method performs best:\n"]},{"cell_type":"code","execution_count":null,"id":"aa158103-b218-4f88-afe4-0216229867cb","metadata":{},"outputs":[],"source":["dict_results = {\n","    \"Models\":[\"Logistic\", \"SVM\", \"Decision Tree\", \"KNN\"], \n","    \"Training Score\": [logreg_cv.best_score_, svm_cv.best_score_, tree_cv.best_score_, knn_cv.best_score_],\n","    \"Test Score\":[logreg_test_score, svm_test_score, tree_test_score, knn_test_score]\n","}\n","df_results = pd.DataFrame(dict_results)\n","print(df_results)\n","print(\"Classification Report for Logistics Regression\")\n","print(logreg_report)\n","print(\"Classification Report for SVM\")\n","print(svm_report)\n","print(\"Classification Report for Decision Tree\")\n","print(tree_report)\n","print(\"Classification Report for KNN\")\n","print(knn_report)"]},{"cell_type":"markdown","id":"6ddc6a71-dfe0-4962-b4eb-0e9ee464e359","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","id":"bb630e0c-4de6-433b-8d3e-642c05cc411f","metadata":{},"source":["[Pratiksha Verma](https://www.linkedin.com/in/pratiksha-verma-6487561b1/)\n"]},{"cell_type":"markdown","id":"20106b57-d037-4570-a616-35e6ff7f3877","metadata":{},"source":["<!--## Change Log--!>\n"]},{"cell_type":"markdown","id":"aa79394d-fa62-4cf6-85f9-616817b75b46","metadata":{},"source":["<!--| Date (YYYY-MM-DD) | Version | Changed By      | Change Description      |\n","| ----------------- | ------- | -------------   | ----------------------- |\n","| 2022-11-09        | 1.0     | Pratiksha Verma | Converted initial version to Jupyterlite|--!>\n"]},{"cell_type":"markdown","id":"6102e6ff-dd69-48fc-b9e2-ac544bf7f452","metadata":{},"source":["### <h3 align=\"center\"> IBM Corporation 2022. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"prev_pub_hash":"5885e7f872892cbaf7ece79588f481df62fe172ff2fb09135787e2cd1c657276"},"nbformat":4,"nbformat_minor":4}
